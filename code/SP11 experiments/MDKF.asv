function Y_MDKF = MDKF(noisy, clean, fs, Tw, Ts, p)

%   noisy: noisy input speech
%   clean: clean input speech
%   fs: sampling frequency
%   Tw: frame duration in s
%   Ts: frame shift in s (overlap)
%   p: MDKF order
%   q: (for coloured noise case)
%
%   MDKF: Apply modulation-domain Kalman filtering for speech enhancement
%   Author: Jia Ying Goh, Imperial College London, January 2017
%   Credits:
%       Mike Brookes, Imperial College London - VOICEBOX: A speech processing toolbox for MATLAB


% % initialisation for coloured noise
% d_v=zeros(q,1);
% d_v(1)=1;
% B=zeros(q);
% for b=1:q-1
%     A(b+1,b)=1;
% end


% noisy modulation signal |Y(n,k)| windowed into short modulation frames, then LPCs and excitation var estimated
% each column is a freq bin
% perform the KF for each freq bin

d=zeros(p,1);
d(1)=1;

% state transition matrix
A=zeros(p);
for a=1:p-1
    A(a+1,a)=1;
end

[W, Nw, Ns] = makeHammingWindow(fs, Tw, Ts);

noisy_fft = rfft(enframe(noisy,W,Ns),Nw,2);     % STFT of noisy signal
clean_fft = rfft(enframe(clean,W,Ns),Nw,2);

noisyfft_mag = abs(noisy_fft);
cleanfft_mag = abs(clean_fft);  % used to estimate LPCs in ideal case

f_noisy = enframe(noisy,W,Ns,'sp');
x = estnoiseg(f_noisy,Ns/fs);   % estimate the noise power spectrum

noisepow = 10*log10(sum(mean(x,1),2));
noisepow

% noiseMagSpectrum = estnoiseg(noisyfft_mag - cleanfft_mag, Ns/fs);
% noisepower = 10*log10(sum(mean(noiseMagSpectrum,1),2));
% noisepower
% 
% size(x)
% size(noiseMagSpectrum)
% size(noisyfft_mag)

% after doing enframe, one row is one time frame (i.e. freq bins along rows)
% take transpose so that freq bins are along columns (easier to represent)
noisyfft_mag = noisyfft_mag';
noisy_fft = noisy_fft'; 
cleanfft_mag = cleanfft_mag';

for m = 1:size(noisy_fft,1)     % each frequency bin (rows of f) has its own KF
    Tw_slow = 10e-3;     % window and shift for each KF
    Ts_slow = 2.5e-3;
    fs_slow = 1/Ts;
    [W_slow, Nw_slow, Ns_slow] = makeHammingWindow(fs_slow, Tw_slow, Ts_slow);
    
    modulation_frames = enframe(noisyfft_mag(m,:), W_slow, Ns_slow);
    angles = enframe(noisy_fft(m,:), W_slow, Ns_slow);
    cleanmag_frames = enframe(cleanfft_mag(m,:), W_slow, Ns_slow);
    
    % assume |noisy| = |signal| + |noise| in modulation domain
    
    state = modulation_frames(1,1:p)';  % initial state - doesn't really matter
    
    
    y = zeros(size(modulation_frames));
    
    for i = 1:size(modulation_frames, 1)        % number of frames
        % LPCs and excitation variance constant within modulation frame
        [ar, excitation_var] = lpcauto(cleanmag_frames(i,:),p);     % LPCs estimated from clean speech
%         [ar, excitation_var] = lpcauto(modulation_frames(i,:),p);   % LPCs estimated from noisy speech
        
        A(1,:) = -ar(2:p+1);
        
        % estimate the noise power spectrum using current modulation frame
        % comment out to use noise estimated from entire signal
        x = estnoiseg((modulation_frames(i,:)),Ns_slow/fs_slow); 
        varV = sum(mean(x,1),2);
        
        varW = excitation_var/length(modulation_frames(i,:));
        
        P = varV*eye(p);              % initial error covariance matrix 
        for j = 1:size(modulation_frames, 2)     % for each sample within modulation frame
            state = A*state;
            P = A*P*A' + varW*(d*d');

            K = P*d*((varV + d'*P*d)^(-1));
            state = state + K*(modulation_frames(i,j) - d'*state);
            P = (eye(p) - K*d')*P;
            y(i,j) = state(1);    % update estimated output
        end
    end

    f_filtered = y .* exp(1i*angle(angles));
    filtered_matrix(m,:) = overlapadd(f_filtered, W_slow, Ns_slow);
end

filtered_matrix = filtered_matrix';     % so that output time signal is col vector
Y_MDKF = overlapadd(irfft(filtered_matrix,Nw,2), W, Ns);


% y = zeros(size(f));
% for m = 1:size(f,1)               % number of time frames (freq domain)
%     [ar, varW] = lpcauto(fc(m,:),p);       % recalculate LPC coefficients, var of excitation and var of noise for each frame
% %     ar = lpcauto(ffc(m,:),p);       % recalculate LPC coefficients, var of excitation and var of noise for each frame
%     A(1,:) = -ar(2:p+1);     
%     
% %     varV = var(f(m,:));
%     varV = sum(mean(x,1),2);        % better than varV = var(f(m,:))/length(f(m,:))
%     
%     varW = varW/length(fc(m,:));    % much better than varW = var(fc(m,:));
% 
%     P = varV*eye(p);              % initial error covariance matrix  
%     
%     % each modulation frame is separate - need to window further?
%     for n = 1:size(f,2)       % number of data points in each frame; all other variables are updated per sample
%         state = A*state;
%         P = A*P*A' + varW*(d*d');
% 
%         K = P*d*((varV + d'*P*d)^(-1));
%         state = state + K*(abs(f(m,n)) - d'*state);
%         P = (eye(p) - K*d')*P;
%         y(m,n) = state(1);    % update estimated output
%     end
%         
%         
% %         Tw_=Tw/4;
% %         Ts_=Ts/4;
% %         Nw_ = round( fs*Tw_*0.001 );                      % frame duration (in samples)
% %         Ns_ = round( fs*Ts_*0.001 );                      % frame shift (in samples)
% %         if Nw_/Ns_==4
% %             W_=hamming(Nw_,'periodic');                   % omit sqrt if OV=4
% %         else
% %             W_=sqrt(hamming(Nw_,'periodic'));
% %         end
% %         W_=W_/sqrt(sum(W_(1:Ns_:Nw_).^2));                   % normalize window
% %         
% %         ff=enframe(f(m,:),W_,Ns_);                          % do processing for each time frame
% %         ffc=enframe(fc(m,:),W_,Ns_);
% % 
% %         yy=zeros(size(ff));
% % 
% %         state=f(m,1:p)';       % initial state
% %         P=varV*eye(p);          % initial error covariance matrix
% %         
% %         for ii=1:size(ff,1)       % number of frames
% %             ar=lpcauto(ff(ii,:),p);       % recalculate LPC coefficients, var of excitation and var of noise for each frame
% %             A(1,:)=-ar(2:p+1);           
% %             varV=var(ff(ii,:));           
% %             varW=var(ffc(ii,:));
% %             if varV==0              % corner case e.g. if clean signal used as input
% %                 yy(ii,:)=ff(ii,:);
% %             else
% %                 for jj=1:size(ff,2)   % number of data points in each frame; all other variables are updated per sample
% %                     state_=A*state;
% %                     P_=A*P*A'+varW*(d*d');
% % 
% %                     K=P_*d*((varV+d'*P_*d)^(-1));
% %                     state=state_+K*(f(ii,jj)-d'*state_);
% %                     P=(eye(p)-K*d')*P_;
% %                     yy(ii,jj)=state(1);  % update estimated output
% %                 end
% %             end
% %         end
% %         
% %         op=overlapadd(yy,W_,Ns_)';
% %         y(m,1:length(op))=op;
%         
% end
% 
% 
% y = y .* exp(1i*angle(f));
% 
% Y_MDKF = overlapadd(irfft(y,Nw,2),W,Ns);  % reconstitute the time waveform
% 
% % y=overlapadd(y,W,Ns);
